 Install dependencies
  import dependencies
setup webcam and canvas
define references tot hose
load app
detect function
drawing utilities
load triangulation
setup triangle path
setup point drawing
add drawMesh to detect function

//   const particlesInit = useCallback(async engine => {
//     console.log(engine);
//     // you can initiate the tsParticles instance (engine) here, adding custom shapes or presets
//     // this loads the tsparticles package bundle, it's the easiest method for getting everything ready
//     // starting from v2 you can add only the features you need reducing the bundle size
//     await loadFull(engine);
// }, []);
// const particlesLoaded = useCallback(async container => {
//   await console.log(container);
// }, []);
  // // setting up references
  // const webcamRef = useRef(null);
  // const canvasRef = useRef(null);

  // // load facemesh
  // const runFacemesh = async() =>{
  //   const net = await facemesh.load({
  //     inputResolution: {width:650, height: 480}, scale: 0.8   /* setup height and width here as of webcam*/ 
  //   })
  //   setInterval(() => {
  //     detect(net)
  //   }, 100);
  // }

  // // detct function
  // const detect = async (net) => { /*if cond is checking that webcam is running & receiving data , readState== 4 means receiving data*/
  //   if(typeof webcamRef.current !== "undefined" && webcamRef.current !== null &&
  //     webcamRef.current.video.readyState === 4){
  //       // get video properties
  //       const video = webcamRef.current.video;  // getting the video
  //       const videoWidth = webcamRef.current.video.videoWidth;  // widht setup for webcam
  //       const videoHeight = webcamRef.current.video.videoHeight;
  //       // set video width
  //       webcamRef.current.video.width = videoWidth;
  //       webcamRef.current.video.height = videoHeight;
  //       // set canvas width
  //       canvasRef.current.width = videoWidth;
  //       canvasRef.current.height = videoHeight;
  //       // make detections   // detect all our facial landmarks
  //       const face = await net.estimateFaces(video);  // line 26
  //       console.log(face);
  //       // get canvas context for drawing
  //       const ctx = canvasRef.current.getContext("2d");
  //       drawMesh(face, ctx);
  //   }
  // }
  // runFacemesh();